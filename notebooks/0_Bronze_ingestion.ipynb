{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "- # Bronze layer\n",
    "    - ## import to parquet or delta lake\n",
    "        - import from API to csv overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "\n",
    "# Paths\n",
    "base_dir = \"../data/openpowerlifting-latest\"\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "# Download ZIP file\n",
    "url = \"https://openpowerlifting.gitlab.io/opl-csv/files/openpowerlifting-latest.zip\"\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "\n",
    "# Extract ZIP to memory\n",
    "with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
    "    # Identify the actual folder name inside the ZIP\n",
    "    folder_names = list({name.split('/')[0] for name in z.namelist() if '/' in name})\n",
    "    if not folder_names:\n",
    "        raise ValueError(\"‚ùå No folder found inside ZIP.\")\n",
    "    \n",
    "    inner_folder_name = folder_names[0]\n",
    "    target_dir = os.path.join(base_dir, inner_folder_name)\n",
    "\n",
    "    # Skip download if this folder already exists\n",
    "    if os.path.exists(target_dir):\n",
    "        print(f\"‚è© Skipping: {target_dir} already exists.\")\n",
    "    else:\n",
    "        print(f\"üì¶ Extracting: {inner_folder_name} ‚Üí {base_dir}\")\n",
    "        z.extractall(base_dir)\n",
    "\n",
    "        # Optional: delete other folders to keep only the latest\n",
    "        for f in os.listdir(base_dir):\n",
    "            f_path = os.path.join(base_dir, f)\n",
    "            if f != inner_folder_name and os.path.isdir(f_path):\n",
    "                print(f\"üóëÔ∏è Deleting old folder: {f_path}\")\n",
    "                shutil.rmtree(f_path)\n",
    "\n",
    "print(\"‚úÖ Finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Set up Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Bronze Transformation\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Base directory where ZIP was extracted\n",
    "base_dir = \"../data/openpowerlifting-latest\"\n",
    "\n",
    "# Find the only subfolder (e.g., openpowerlifting-2025-05-31)\n",
    "subfolders = [f for f in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, f))]\n",
    "if not subfolders:\n",
    "    raise FileNotFoundError(\"‚ùå No data folder found in openpowerlifting-latest/\")\n",
    "latest_folder = subfolders[0]\n",
    "\n",
    "# Path to the CSV file\n",
    "csv_path = os.path.join(base_dir, latest_folder, \"openpowerlifting-2025-05-31.csv\")\n",
    "\n",
    "# In case the CSV filename varies slightly, search for it\n",
    "if not os.path.exists(csv_path):\n",
    "    files = os.listdir(os.path.join(base_dir, latest_folder))\n",
    "    csv_files = [f for f in files if f.endswith(\".csv\")]\n",
    "    if not csv_files:\n",
    "        raise FileNotFoundError(\"‚ùå No CSV file found in the latest folder.\")\n",
    "    csv_path = os.path.join(base_dir, latest_folder, csv_files[0])\n",
    "\n",
    "print(f\"üìÇ Reading: {csv_path}\")\n",
    "\n",
    "# Read CSV into Spark DataFrame\n",
    "df = spark.read.csv(csv_path, header=True, inferSchema=True)\n",
    "\n",
    "# Save to Parquet in the bronze zone\n",
    "bronze_dir = \"../data/bronze\"\n",
    "os.makedirs(bronze_dir, exist_ok=True)\n",
    "df.write.mode(\"overwrite\").parquet(os.path.join(bronze_dir, \"openpowerlifting_bronze.parquet\"))\n",
    "\n",
    "print(\"‚úÖ Saved Parquet to bronze zone.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
